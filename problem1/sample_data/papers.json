[
  {
    "arxiv_id": "9905014v1",
    "title": "Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition",
    "authors": [
      "Thomas G. Dietterich"
    ],
    "abstract": "This paper presents the MAXQ approach to hierarchical reinforcement learning based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The paper defines the MAXQ hierarchy, proves formal results on its representational power, and establishes five conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges wih probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the five kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster than flat Q learning. The fact that MAXQ learns a representation of the value function has an important benefit: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the effectiveness of this non-hierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoffs in hierarchical reinforcement learning.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "1999-05-21T14:26:07Z",
    "updated": "1999-05-21T14:26:07Z",
    "abstract_stats": {
      "total_words": 216,
      "unique_words": 111,
      "total_sentences": 7,
      "avg_words_per_sentence": 30.857,
      "avg_word_length": 5.574
    }
  },
  {
    "arxiv_id": "9905015v1",
    "title": "State Abstraction in MAXQ Hierarchical Reinforcement Learning",
    "authors": [
      "Thomas G. Dietterich"
    ],
    "abstract": "Many researchers have explored methods for hierarchical reinforcement learning (RL) with temporal abstractions, in which abstract actions are defined that can perform many primitive actions before terminating. However, little is known about learning with state abstractions, in which aspects of the state space are ignored. In previous work, we developed the MAXQ method for hierarchical RL. In this paper, we define five conditions under which state abstraction can be combined with the MAXQ value function decomposition. We prove that the MAXQ-Q learning algorithm converges under these conditions and show experimentally that state abstraction is important for the successful application of MAXQ-Q learning.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "1999-05-21T14:49:39Z",
    "updated": "1999-05-21T14:49:39Z",
    "abstract_stats": {
      "total_words": 102,
      "unique_words": 65,
      "total_sentences": 5,
      "avg_words_per_sentence": 20.4,
      "avg_word_length": 5.853
    }
  },
  {
    "arxiv_id": "0001004v1",
    "title": "Multiplicative Algorithm for Orthgonal Groups and Independent Component Analysis",
    "authors": [
      "Toshinao Akuzawa"
    ],
    "abstract": "The multiplicative Newton-like method developed by the author et al. is extended to the situation where the dynamics is restricted to the orthogonal group. A general framework is constructed without specifying the cost function. Though the restriction to the orthogonal groups makes the problem somewhat complicated, an explicit expression for the amount of individual jumps is obtained. This algorithm is exactly second-order-convergent. The global instability inherent in the Newton method is remedied by a Levenberg-Marquardt-type variation. The method thus constructed can readily be applied to the independent component analysis. Its remarkable performance is illustrated by a numerical simulation.",
    "categories": [
      "cs.LG",
      "G.1.6"
    ],
    "published": "2000-01-07T06:20:53Z",
    "updated": "2000-01-07T06:20:53Z",
    "abstract_stats": {
      "total_words": 98,
      "unique_words": 68,
      "total_sentences": 8,
      "avg_words_per_sentence": 12.25,
      "avg_word_length": 6.092
    }
  },
  {
    "arxiv_id": "0002006v1",
    "title": "Multiplicative Nonholonomic/Newton -like Algorithm",
    "authors": [
      "Toshinao Akuzawa",
      "Noboru Murata"
    ],
    "abstract": "We construct new algorithms from scratch, which use the fourth order cumulant of stochastic variables for the cost function. The multiplicative updating rule here constructed is natural from the homogeneous nature of the Lie group and has numerous merits for the rigorous treatment of the dynamics. As one consequence, the second order convergence is shown. For the cost function, functions invariant under the componentwise scaling are choosen. By identifying points which can be transformed to each other by the scaling, we assume that the dynamics is in a coset space. In our method, a point can move toward any direction in this coset. Thus, no prewhitening is required.",
    "categories": [
      "cs.LG",
      "G.1.6"
    ],
    "published": "2000-02-09T06:44:28Z",
    "updated": "2000-02-09T06:44:28Z",
    "abstract_stats": {
      "total_words": 108,
      "unique_words": 76,
      "total_sentences": 7,
      "avg_words_per_sentence": 15.429,
      "avg_word_length": 5.13
    }
  },
  {
    "arxiv_id": "0009001v3",
    "title": "Complexity analysis for algorithmically simple strings",
    "authors": [
      "Andrei N. Soklakov"
    ],
    "abstract": "Given a reference computer, Kolmogorov complexity is a well defined function on all binary strings. In the standard approach, however, only the asymptotic properties of such functions are considered because they do not depend on the reference computer. We argue that this approach can be more useful if it is refined to include an important practical case of simple binary strings. Kolmogorov complexity calculus may be developed for this case if we restrict the class of available reference computers. The interesting problem is to define a class of computers which is restricted in a {\\it natural} way modeling the real-life situation where only a limited class of computers is physically available to us. We give an example of what such a natural restriction might look like mathematically, and show that under such restrictions some error terms, even logarithmic in complexity, can disappear from the standard complexity calculus. Keywords: Kolmogorov complexity; Algorithmic information theory.",
    "categories": [
      "cs.LG",
      "E.4; F.2; I.2"
    ],
    "published": "2000-09-05T18:54:58Z",
    "updated": "2002-02-26T01:51:09Z",
    "abstract_stats": {
      "total_words": 153,
      "unique_words": 95,
      "total_sentences": 7,
      "avg_words_per_sentence": 21.857,
      "avg_word_length": 5.418
    }
  },
  {
    "arxiv_id": "0009007v1",
    "title": "Robust Classification for Imprecise Environments",
    "authors": [
      "Foster Provost",
      "Tom Fawcett"
    ],
    "abstract": "In real-world environments it usually is difficult to specify target operating conditions precisely, for example, target misclassification costs. This uncertainty makes building robust classification systems problematic. We show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions. In some cases, the performance of the hybrid actually can surpass that of the best known classifier. This robust performance extends across a wide variety of comparison frameworks, including the optimization of metrics such as accuracy, expected cost, lift, precision, recall, and workforce utilization. The hybrid also is efficient to build, to store, and to update. The hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. The ROC convex hull (ROCCH) method combines techniques from ROC analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. The method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. Finally, we point to empirical evidence that a robust hybrid classifier indeed is needed for many real-world problems.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2000-09-13T21:09:47Z",
    "updated": "2000-09-13T21:09:47Z",
    "abstract_stats": {
      "total_words": 198,
      "unique_words": 115,
      "total_sentences": 10,
      "avg_words_per_sentence": 19.8,
      "avg_word_length": 5.763
    }
  },
  {
    "arxiv_id": "0011032v1",
    "title": "Top-down induction of clustering trees",
    "authors": [
      "Hendrik Blockeel",
      "Luc De Raedt",
      "Jan Ramon"
    ],
    "abstract": "An approach to clustering is presented that adapts the basic top-down induction of decision trees method towards clustering. To this aim, it employs the principles of instance based learning. The resulting methodology is implemented in the TIC (Top down Induction of Clustering trees) system for first order clustering. The TIC system employs the first order logical decision tree representation of the inductive logic programming system Tilde. Various experiments with TIC are presented, in both propositional and relational domains.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2000-11-21T21:51:01Z",
    "updated": "2000-11-21T21:51:01Z",
    "abstract_stats": {
      "total_words": 78,
      "unique_words": 52,
      "total_sentences": 5,
      "avg_words_per_sentence": 15.6,
      "avg_word_length": 5.744
    }
  },
  {
    "arxiv_id": "0011044v1",
    "title": "Scaling Up Inductive Logic Programming by Learning from Interpretations",
    "authors": [
      "Hendrik Blockeel",
      "Luc De Raedt",
      "Nico Jacobs",
      "Bart Demoen"
    ],
    "abstract": "When comparing inductive logic programming (ILP) and attribute-value learning techniques, there is a trade-off between expressive power and efficiency. Inductive logic programming techniques are typically more expressive but also less efficient. Therefore, the data sets handled by current inductive logic programming systems are small according to general standards within the data mining community. The main source of inefficiency lies in the assumption that several examples may be related to each other, so they cannot be handled independently. Within the learning from interpretations framework for inductive logic programming this assumption is unnecessary, which allows to scale up existing ILP algorithms. In this paper we explain this learning setting in the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that learning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning, while maintaining its efficiency to a large extent (which is not the case in the classical ILP setting). As a case study, we present two alternative implementations of the ILP system Tilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which loads all data in main memory, and Tilde-LDS, which loads the examples one by one. We experimentally compare the implementations, showing Tilde-LDS can handle large data sets (in the order of 100,000 examples or 100 MB) and indeed scales up linearly in the number of examples.",
    "categories": [
      "cs.LG",
      "I.2.6 ; I.2.3"
    ],
    "published": "2000-11-29T12:14:50Z",
    "updated": "2000-11-29T12:14:50Z",
    "abstract_stats": {
      "total_words": 234,
      "unique_words": 129,
      "total_sentences": 9,
      "avg_words_per_sentence": 26.0,
      "avg_word_length": 5.611
    }
  },
  {
    "arxiv_id": "0103003v1",
    "title": "Learning Policies with External Memory",
    "authors": [
      "Leonid Peshkin",
      "Nicolas Meuleau",
      "Leslie Kaelbling"
    ],
    "abstract": "In order for an agent to perform well in partially observable domains, it is usually necessary for actions to depend on the history of observations. In this paper, we explore a {\\it stigmergic} approach, in which the agent's actions include the ability to set and clear bits in an external memory, and the external memory is included as part of the input to the agent. In this case, we need to learn a reactive policy in a highly non-Markovian domain. We explore two algorithms: SARSA(\\lambda), which has had empirical success in partially observable domains, and VAPS, a new algorithm due to Baird and Moore, with convergence guarantees in partially observable domains. We compare the performance of these two algorithms on benchmark problems.",
    "categories": [
      "cs.LG",
      "I.2.8;I.2.6;I.2.11;I.2;I.2.3"
    ],
    "published": "2001-03-02T01:55:46Z",
    "updated": "2001-03-02T01:55:46Z",
    "abstract_stats": {
      "total_words": 124,
      "unique_words": 73,
      "total_sentences": 5,
      "avg_words_per_sentence": 24.8,
      "avg_word_length": 4.847
    }
  },
  {
    "arxiv_id": "0110036v1",
    "title": "Efficient algorithms for decision tree cross-validation",
    "authors": [
      "Hendrik Blockeel",
      "Jan Struyf"
    ],
    "abstract": "Cross-validation is a useful and generally applicable technique often employed in machine learning, including decision tree induction. An important disadvantage of straightforward implementation of the technique is its computational overhead. In this paper we show that, for decision trees, the computational overhead of cross-validation can be reduced significantly by integrating the cross-validation with the normal decision tree induction process. We discuss how existing decision tree algorithms can be adapted to this aim, and provide an analysis of the speedups these adaptations may yield. The analysis is supported by experimental results.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2001-10-17T15:45:23Z",
    "updated": "2001-10-17T15:45:23Z",
    "abstract_stats": {
      "total_words": 90,
      "unique_words": 60,
      "total_sentences": 5,
      "avg_words_per_sentence": 18.0,
      "avg_word_length": 6.111
    }
  }
]